\documentclass[report.tex]{subfiles}
\begin{document}

\chapter{Detailed Design and Implementation} % (fold)
\label{cha:detailed_design_and_implementation}

% ==============================================================================
% ==============================================================================

\section{Implementation Languages} % (fold)
\label{sec:implementation_languages}

\subsection{Java 8} % (fold)
\label{sub:java_8}
The compiler was created using Java version 8. The primary motivation behind
using Java was my familiarity with the language and the libraries \& frameworks
available. The complex nature of this project meant that I did not want to spend
time getting familiar with a language such as C++, while I knew that I take
advantage of a build system like Maven to handle the inevitable dependency and
testing suites I would require.
% subsection java_8 (end)

\subsection{PRISM} % (fold)
\label{sub:prism}
PRISM (\url{http://prismmodelchecker.org}) was naturally required for the
implementation of the compiler. It was necessary to ensure that the models being
generated by the compiler were valid and were accurately reflecting the set-up
specified in a .qgrady file.
% subsection prism (end)

% ==============================================================================

% subsection subsection_name (end)
% section implementation_languages (end)
\section{Tools} % (fold)
\label{sec:tools}
The Q'Grady compiler makes use of several libraries to assist in development.
These have been outlined below, outlining their function and why they were used
for the development of the compiler.

\subsection{Cup} % (fold)
\label{sub:cup}
Cup (\url{http://www2.cs.tum.edu/projects/cup}) is a parser generator that was
used to convert the Q'Grady grammar as specified in the .cup file into Java
classes that could be inserted into the Q'Grady compiler.
% subsection cup (end)

\subsection{JFlex} % (fold)
\label{sub:jflex}
JFlex (\url{http://jflex.de})is a scanner generatorfor Java. It generated an
additional Java class for the compiler, matching tokens from the scanned input
to regular expressions outlined in the .flex file.
% subsection jflex (end)

\subsection{Apache Maven} % (fold)
\label{sub:apache_maven}
Maven (\url{http://maven.apache.org}) was used primarily for handling dependency
injection. Plugins for JFlex and Cup were used to make the use of the libraries
a lot easier, since they would handle executing the generation of classes while
compiling my own Java classes. It also allowed me to automate JUnit testing
during the compilation and packaging stages.
% subsection apache_maven (end)

\subsection{Apache Commons CLI \& IO} % (fold)
\label{sub:apache_commons_cli}
The Apache Commons CLI (\url{http://commons.apache.org/proper/commons-cli}) was
used for handling the parsing of command line arguments when executing the
compiler. It was used for handling the logic behind managing the presence of
the mandatory and optional arguments for the compiler, such as the source and
destination files.

The Commons IO (\url{http://commons.apache.org/proper/commons-io}) library was
required for methods relating to handling files, such as ensuring that files
had the proper extension when required.
% subsection apache_commons_cli (end)

\subsection{JUnit} % (fold)
\label{sub:junit}
JUnit (\url{http://junit.org}) was used for testing the Java code, ensuring that
features of the compiler were accurate and doing what was intended.
% subsection junit (end)
% section tools (end)

% ==============================================================================

\section{Implementation} % (fold)
\label{sec:implementation}
\subsection{The Box Class} % (fold)
\label{sub:the_box_class}
The first problem to tackle as part of the compiler was an obvious one: how to
store the box set-up as a Java object to be used throughout the compilation
process. This included the storage of the probability distribution, the inputs
and outputs required, and all the methods required for calculating the other
probabilities.

\subsubsection{Storing the Distribution} % (fold)
\label{ssub:storing_the_distribution}
The first method of storing the distribution was used when the Q'Grady language
had no way of showing the number of inputs/outputs or their ranges, it had to be
assumed based on the size of the matrix. Thus, the initial storage was a
\texttt{Map} of \texttt{Instance}s to the probability of that \texttt{Instance}.

The \texttt{Instance} consisted of two arrays that were the input and output
values of the this possible outcome. As the language was extended to incorporate
the new features, this method was replaced with the more simple solution of
simply storing the matrix parsed by the compiler as a two-dimensional array
instead.
% subsubsection storing_the_distribution (end)

\subsubsection{Reduced Probability} % (fold)
\label{ssub:reduced_probability}
As touched upon in Section \ref{sub:non_signalling}, the reduced probability is
the probability of a single output value given a single input value, requiring
a way to ignore the other values.

\lstinputlisting[numbers=left, basicstyle=\ttfamily\footnotesize,
caption={Reduced Probability method.}, captionpos=b, label=reduced_method,
frame=single, language=Java, breaklines=true]{files/reduced.java} 

The method \texttt{public double prob(int inputIndex, int input,
int outputIndex, int output)} is used to achieve this in the \texttt{Box} class.
It starts by systematically going through every possible input and output, and
accumulating the probabilities of all that match the given input and output
based on the index and value provided. It then divided that sum by
\(inputRange ^ (inputs.size() - 1)\) to provide the reduced probability. This
method means that it is flexible for set-ups beyond that of the basic boxes such
as the PR box.
% subsubsection reduced_probability (end)

\subsubsection{Normalised Probability} % (fold)
\label{ssub:normalised_probability}
The normalised probability saw difficulties in implementing the handling of more
than two variables. It is very simple to handle the case were all but one output
is known (and the same for handling a single output like in the reduced
probabilities). Indeed, attempts to change the normalising method to handle the
use case where the file generator is handling the stages where the second
output's probabilities are being normalised after deciding the first output is
decided.

\lstinputlisting[numbers=left, basicstyle=\ttfamily\footnotesize,
caption={Normalised Probability method.}, captionpos=b, label=normalised_method,
frame=single, language=Java]{files/normalised.java} 

% subsubsection normalised_probability (end)

\subsubsection{Helper Methods} % (fold)
\label{ssub:helper_methods}
Two static helper methods were required to allow for integer to array
conversion, flexible to handle any base that acted as the range for inputs and
outputs. These were already necessary for the file generation and other parts
of the system, meaning their inclusion was not a major problem, and was in fact
straight forward.
% subsubsection helper_methods (end)
% subsection the_box_class (end)

\subsection{The Compiler} % (fold)
\label{sub:the_compiler}

% subsection the_compiler (end)
% section implementation (end)
% ==============================================================================
% ==============================================================================
% chapter detailed_design_and_implementation (end)
\newpage
\end{document}